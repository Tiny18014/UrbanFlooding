{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e824b72",
   "metadata": {},
   "source": [
    "# Urban Flood Forecasting - Part 1: Data Loading & Basic Statistics\n",
    "\n",
    "**Objective:** Load the urban flood forecasting dataset, understand its structure, calculate basic statistics, and compute standardization parameters needed for model training.\n",
    "\n",
    "## Tasks:\n",
    "1. Load static files for Model 1 and Model 2\n",
    "2. Load sample events to understand dynamic data\n",
    "3. Calculate network statistics (node counts, edge counts, connections)\n",
    "4. Analyze sequence lengths across events\n",
    "5. Check for missing values\n",
    "6. **CRITICAL:** Calculate standardization values for water levels (needed for loss function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e3eb3b",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467a4545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Pandas version: 2.3.3\n",
      "NumPy version: 2.2.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cb7398",
   "metadata": {},
   "source": [
    "## 2. Define File Paths and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c5f8a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model 1 directory: c:\\Users\\shubh\\OneDrive\\Desktop\\UrbanFlooding\\Models\\Model_1\n",
      "âœ“ Model 2 directory: c:\\Users\\shubh\\OneDrive\\Desktop\\UrbanFlooding\\Models\\Model_2\n",
      "âœ“ Output directory: c:\\Users\\shubh\\OneDrive\\Desktop\\UrbanFlooding\\analysis_outputs\n",
      "\n",
      "Directories exist:\n",
      "  Model 1: True\n",
      "  Model 2: True\n"
     ]
    }
   ],
   "source": [
    "# Base directory\n",
    "BASE_DIR = Path(r\"c:\\Users\\shubh\\OneDrive\\Desktop\\UrbanFlooding\\Models\")\n",
    "\n",
    "# Model directories\n",
    "MODEL_1_DIR = BASE_DIR / \"Model_1\"\n",
    "MODEL_2_DIR = BASE_DIR / \"Model_2\"\n",
    "\n",
    "# Sample events to load for initial exploration\n",
    "SAMPLE_EVENTS = [\"event_1\", \"event_10\", \"event_20\"]\n",
    "\n",
    "# Create output directory for results\n",
    "OUTPUT_DIR = Path(r\"c:\\Users\\shubh\\OneDrive\\Desktop\\UrbanFlooding\\analysis_outputs\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"âœ“ Model 1 directory: {MODEL_1_DIR}\")\n",
    "print(f\"âœ“ Model 2 directory: {MODEL_2_DIR}\")\n",
    "print(f\"âœ“ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"\\nDirectories exist:\")\n",
    "print(f\"  Model 1: {MODEL_1_DIR.exists()}\")\n",
    "print(f\"  Model 2: {MODEL_2_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923bafcf",
   "metadata": {},
   "source": [
    "## 3. Load Static Files for Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb0ce90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING STATIC FILES FOR MODEL 1\n",
      "================================================================================\n",
      "\n",
      "âœ“ All static files loaded successfully!\n",
      "\n",
      "Static File Shapes:\n",
      "  1D Nodes: (17, 7)\n",
      "  2D Nodes: (3716, 10)\n",
      "  1D Edges: (16, 8)\n",
      "  2D Edges: (7935, 6)\n",
      "  1D Edge Index: (16, 3)\n",
      "  2D Edge Index: (7935, 3)\n",
      "  1D-2D Connections: (16, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOADING STATIC FILES FOR MODEL 1\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load static node files\n",
    "m1_nodes_1d = pd.read_csv(MODEL_1_DIR / \"train\" / \"1d_nodes_static.csv\")\n",
    "m1_nodes_2d = pd.read_csv(MODEL_1_DIR / \"train\" / \"2d_nodes_static.csv\")\n",
    "\n",
    "# Load static edge files\n",
    "m1_edges_1d = pd.read_csv(MODEL_1_DIR / \"train\" / \"1d_edges_static.csv\")\n",
    "m1_edges_2d = pd.read_csv(MODEL_1_DIR / \"train\" / \"2d_edges_static.csv\")\n",
    "\n",
    "# Load edge indices (connectivity)\n",
    "m1_edge_index_1d = pd.read_csv(MODEL_1_DIR / \"train\" / \"1d_edge_index.csv\")\n",
    "m1_edge_index_2d = pd.read_csv(MODEL_1_DIR / \"train\" / \"2d_edge_index.csv\")\n",
    "\n",
    "# Load 1D-2D coupling connections\n",
    "m1_connections_1d2d = pd.read_csv(MODEL_1_DIR / \"train\" / \"1d2d_connections.csv\")\n",
    "\n",
    "# Load dataset summary\n",
    "m1_summary = pd.read_csv(MODEL_1_DIR / \"train\" / \"dataset_summary.csv\")\n",
    "\n",
    "print(\"\\nâœ“ All static files loaded successfully!\\n\")\n",
    "\n",
    "# Display shapes\n",
    "print(\"Static File Shapes:\")\n",
    "print(f\"  1D Nodes: {m1_nodes_1d.shape}\")\n",
    "print(f\"  2D Nodes: {m1_nodes_2d.shape}\")\n",
    "print(f\"  1D Edges: {m1_edges_1d.shape}\")\n",
    "print(f\"  2D Edges: {m1_edges_2d.shape}\")\n",
    "print(f\"  1D Edge Index: {m1_edge_index_1d.shape}\")\n",
    "print(f\"  2D Edge Index: {m1_edge_index_2d.shape}\")\n",
    "print(f\"  1D-2D Connections: {m1_connections_1d2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54218283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "1D NODES STATIC (Sample)\n",
      "================================================================================\n",
      "Columns: ['node_idx', 'position_x', 'position_y', 'depth', 'invert_elevation', 'surface_elevation', 'base_area']\n",
      "   node_idx  position_x  position_y     depth  invert_elevation  \\\n",
      "0         0   802465.60   349898.84  8.977997           292.342   \n",
      "1         1   802528.94   349713.56  6.195984           295.164   \n",
      "2         2   802430.44   349608.60  5.480011           297.610   \n",
      "3         3   802420.06   349242.25  4.699982           310.450   \n",
      "4         4   802338.94   349292.66  3.593994           313.376   \n",
      "\n",
      "   surface_elevation  base_area  \n",
      "0             301.32      12.56  \n",
      "1             301.36      12.56  \n",
      "2             303.09      12.56  \n",
      "3             315.15      12.56  \n",
      "4             316.97      12.56  \n",
      "\n",
      "================================================================================\n",
      "2D NODES STATIC (Sample)\n",
      "================================================================================\n",
      "Columns: ['node_idx', 'position_x', 'position_y', 'area', 'roughness', 'min_elevation', 'elevation', 'aspect', 'curvature', 'flow_accumulation']\n",
      "   node_idx  position_x  position_y       area  roughness  min_elevation  \\\n",
      "0         0   803051.56   350382.44  825.63544       0.06      329.75012   \n",
      "1         1   803076.56   350382.44  616.87900       0.06      329.84910   \n",
      "2         2   803101.56   350382.44  611.14510       0.06      329.69390   \n",
      "3         3   803126.56   350382.44  605.41113       0.06      329.28427   \n",
      "4         4   803151.56   350382.44  599.67720       0.06      328.35257   \n",
      "\n",
      "   elevation     aspect  curvature  flow_accumulation  \n",
      "0  331.09375  185.94380   0.000082                8.0  \n",
      "1  330.90625  182.54686   0.000036                1.0  \n",
      "2  330.56250  140.86070   0.000004                2.0  \n",
      "3  330.00000   89.00771   0.000022                1.0  \n",
      "4  328.81250   96.00465   0.000061                3.0  \n"
     ]
    }
   ],
   "source": [
    "# Display column names and first few rows\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"1D NODES STATIC (Sample)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Columns: {list(m1_nodes_1d.columns)}\")\n",
    "print(m1_nodes_1d.head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"2D NODES STATIC (Sample)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Columns: {list(m1_nodes_2d.columns)}\")\n",
    "print(m1_nodes_2d.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f429d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATASET SUMMARY (Model 1)\n",
      "================================================================================\n",
      "                             0\n",
      "dataset_mode             train\n",
      "num_2d_nodes              3716\n",
      "num_2d_edges              7935\n",
      "num_1d_nodes                17\n",
      "num_1d_edges                16\n",
      "num_1d2d_connections        16\n",
      "num_events                  68\n",
      "total_rollout_timesteps  15571\n",
      "timestep_interval          300\n",
      "previous_timesteps           1\n",
      "normalized               False\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATASET SUMMARY (Model 1)\")\n",
    "print(\"=\" * 80)\n",
    "print(m1_summary.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e31348",
   "metadata": {},
   "source": [
    "## 4. Load Sample Event Dynamic Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "068705fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING SAMPLE EVENT DYNAMIC FILES (Model 1)\n",
      "================================================================================\n",
      "\n",
      "Loading event_1...\n",
      "  1d_nodes_dynamic: (1598, 4)\n",
      "  2d_nodes_dynamic: (349304, 5)\n",
      "  1d_edges_dynamic: (1504, 4)\n",
      "  2d_edges_dynamic: (745890, 4)\n",
      "  timesteps: (94, 2)\n",
      "\n",
      "Loading event_10...\n",
      "  1d_nodes_dynamic: (3485, 4)\n",
      "  2d_nodes_dynamic: (761780, 5)\n",
      "  1d_edges_dynamic: (3280, 4)\n",
      "  2d_edges_dynamic: (1626675, 4)\n",
      "  timesteps: (205, 2)\n",
      "\n",
      "Loading event_20...\n",
      "  1d_nodes_dynamic: (3485, 4)\n",
      "  2d_nodes_dynamic: (761780, 5)\n",
      "  1d_edges_dynamic: (3280, 4)\n",
      "  2d_edges_dynamic: (1626675, 4)\n",
      "  timesteps: (205, 2)\n",
      "\n",
      "âœ“ Loaded 3 sample events\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOADING SAMPLE EVENT DYNAMIC FILES (Model 1)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Dictionary to store sample event data\n",
    "sample_events_data = {}\n",
    "\n",
    "for event in SAMPLE_EVENTS:\n",
    "    event_dir = MODEL_1_DIR / \"train\" / event\n",
    "    \n",
    "    if event_dir.exists():\n",
    "        print(f\"\\nLoading {event}...\")\n",
    "        \n",
    "        sample_events_data[event] = {\n",
    "            '1d_nodes_dynamic': pd.read_csv(event_dir / \"1d_nodes_dynamic_all.csv\"),\n",
    "            '2d_nodes_dynamic': pd.read_csv(event_dir / \"2d_nodes_dynamic_all.csv\"),\n",
    "            '1d_edges_dynamic': pd.read_csv(event_dir / \"1d_edges_dynamic_all.csv\"),\n",
    "            '2d_edges_dynamic': pd.read_csv(event_dir / \"2d_edges_dynamic_all.csv\"),\n",
    "            'timesteps': pd.read_csv(event_dir / \"timesteps.csv\")\n",
    "        }\n",
    "        \n",
    "        # Print shapes\n",
    "        for key, df in sample_events_data[event].items():\n",
    "            print(f\"  {key}: {df.shape}\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ Warning: {event} directory not found!\")\n",
    "\n",
    "print(f\"\\nâœ“ Loaded {len(sample_events_data)} sample events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed73d764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVENT 1 - 1D NODES DYNAMIC (Sample)\n",
      "================================================================================\n",
      "Columns: ['timestep', 'node_idx', 'water_level', 'inlet_flow']\n",
      "   timestep  node_idx  water_level  inlet_flow\n",
      "0         0         0    294.87430    0.000000\n",
      "1         0         1    288.22095    0.000000\n",
      "2         0         2    311.72510    3.189905\n",
      "3         0         3    310.67368    1.829733\n",
      "4         0         4    311.72390    0.000000\n",
      "5         0         5    313.18546    0.000000\n",
      "6         0         6    324.91650   -0.000000\n",
      "7         0         7    345.26065    0.000000\n",
      "8         0         8    347.95245   -0.000000\n",
      "9         0         9    314.20856    0.000000\n",
      "\n",
      "================================================================================\n",
      "EVENT 1 - 2D NODES DYNAMIC (Sample)\n",
      "================================================================================\n",
      "Columns: ['timestep', 'node_idx', 'rainfall', 'water_level', 'water_volume']\n",
      "   timestep  node_idx  rainfall  water_level  water_volume\n",
      "0         0         0  0.143333   329.936523      2.127534\n",
      "1         0         1  0.143333   329.985474      0.835427\n",
      "2         0         2  0.143333   329.880676      1.661489\n",
      "3         0         3  0.143333   329.431030      2.059574\n",
      "4         0         4  0.143333   328.498291      1.802438\n",
      "5         0         5  0.143333   328.231567      5.108905\n",
      "6         0         6  0.143333   327.713989      0.945154\n",
      "7         0         7  0.143333   327.422180      2.499798\n",
      "8         0         8  0.143333   327.475586      1.144473\n",
      "9         0         9  0.143333   328.636963      1.922066\n"
     ]
    }
   ],
   "source": [
    "# Display sample from event_1 dynamic data\n",
    "event_1_data = sample_events_data['event_1']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EVENT 1 - 1D NODES DYNAMIC (Sample)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Columns: {list(event_1_data['1d_nodes_dynamic'].columns)}\")\n",
    "print(event_1_data['1d_nodes_dynamic'].head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EVENT 1 - 2D NODES DYNAMIC (Sample)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Columns: {list(event_1_data['2d_nodes_dynamic'].columns)}\")\n",
    "print(event_1_data['2d_nodes_dynamic'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61115883",
   "metadata": {},
   "source": [
    "## 5. Calculate Basic Network Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fbd2871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL 1 - NETWORK STATISTICS\n",
      "================================================================================\n",
      "Num 1D Nodes: 17\n",
      "Num 2D Nodes: 3,716\n",
      "Num 1D Edges: 16\n",
      "Num 2D Edges: 7,935\n",
      "Num 1D2D Connections: 16\n",
      "Total Nodes: 3,733\n",
      "Total Edges: 7,951\n",
      "\n",
      "Network Ratios:\n",
      "  1D/2D Node Ratio: 1:218.6\n",
      "  1D/2D Edge Ratio: 1:495.9\n",
      "  Avg connections per 1D node: 0.94\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"MODEL 1 - NETWORK STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate counts\n",
    "stats_m1 = {\n",
    "    'num_1d_nodes': len(m1_nodes_1d),\n",
    "    'num_2d_nodes': len(m1_nodes_2d),\n",
    "    'num_1d_edges': len(m1_edges_1d),\n",
    "    'num_2d_edges': len(m1_edges_2d),\n",
    "    'num_1d2d_connections': len(m1_connections_1d2d),\n",
    "    'total_nodes': len(m1_nodes_1d) + len(m1_nodes_2d),\n",
    "    'total_edges': len(m1_edges_1d) + len(m1_edges_2d),\n",
    "}\n",
    "\n",
    "# Display statistics\n",
    "for key, value in stats_m1.items():\n",
    "    print(f\"{key.replace('_', ' ').title()}: {value:,}\")\n",
    "\n",
    "print(f\"\\nNetwork Ratios:\")\n",
    "print(f\"  1D/2D Node Ratio: 1:{stats_m1['num_2d_nodes'] / stats_m1['num_1d_nodes']:.1f}\")\n",
    "print(f\"  1D/2D Edge Ratio: 1:{stats_m1['num_2d_edges'] / stats_m1['num_1d_edges']:.1f}\")\n",
    "print(f\"  Avg connections per 1D node: {stats_m1['num_1d2d_connections'] / stats_m1['num_1d_nodes']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90828a7",
   "metadata": {},
   "source": [
    "## 6. Analyze Sequence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b71de572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SEQUENCE LENGTH ANALYSIS (Sample Events)\n",
      "================================================================================\n",
      "\n",
      "event_1:\n",
      "  Timesteps file length: 94\n",
      "  1D nodes timesteps: 94\n",
      "  2D nodes timesteps: 94\n",
      "  Duration: 2025-10-02 04:00:00 â†’ 2025-10-02 11:45:00\n",
      "\n",
      "event_10:\n",
      "  Timesteps file length: 205\n",
      "  1D nodes timesteps: 205\n",
      "  2D nodes timesteps: 205\n",
      "  Duration: 2025-10-02 04:00:00 â†’ 2025-10-02 21:00:00\n",
      "\n",
      "event_20:\n",
      "  Timesteps file length: 205\n",
      "  1D nodes timesteps: 205\n",
      "  2D nodes timesteps: 205\n",
      "  Duration: 2025-10-02 04:00:00 â†’ 2025-10-02 21:00:00\n",
      "\n",
      "================================================================================\n",
      "SEQUENCE LENGTH SUMMARY\n",
      "================================================================================\n",
      "Min sequence length: 94 timesteps\n",
      "Max sequence length: 205 timesteps\n",
      "Mean sequence length: 168.0 timesteps\n",
      "Median sequence length: 205.0 timesteps\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SEQUENCE LENGTH ANALYSIS (Sample Events)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "sequence_lengths = {}\n",
    "\n",
    "for event_name, data in sample_events_data.items():\n",
    "    # Calculate sequence length from timesteps\n",
    "    seq_len = len(data['timesteps'])\n",
    "    sequence_lengths[event_name] = seq_len\n",
    "    \n",
    "    # Verify consistency across dynamic files\n",
    "    n_timesteps_1d_nodes = data['1d_nodes_dynamic']['timestep'].nunique()\n",
    "    n_timesteps_2d_nodes = data['2d_nodes_dynamic']['timestep'].nunique()\n",
    "    \n",
    "    print(f\"\\n{event_name}:\")\n",
    "    print(f\"  Timesteps file length: {seq_len}\")\n",
    "    print(f\"  1D nodes timesteps: {n_timesteps_1d_nodes}\")\n",
    "    print(f\"  2D nodes timesteps: {n_timesteps_2d_nodes}\")\n",
    "    print(f\"  Duration: {data['timesteps']['timestamp'].iloc[0]} â†’ {data['timesteps']['timestamp'].iloc[-1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SEQUENCE LENGTH SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "seq_lengths_array = np.array(list(sequence_lengths.values()))\n",
    "print(f\"Min sequence length: {seq_lengths_array.min()} timesteps\")\n",
    "print(f\"Max sequence length: {seq_lengths_array.max()} timesteps\")\n",
    "print(f\"Mean sequence length: {seq_lengths_array.mean():.1f} timesteps\")\n",
    "print(f\"Median sequence length: {np.median(seq_lengths_array):.1f} timesteps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e6d5fa",
   "metadata": {},
   "source": [
    "## 7. Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b5638b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MISSING VALUE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "--- STATIC FILES ---\n",
      "\n",
      "âœ“ 1D Nodes Static: No missing values\n",
      "\n",
      "âš ï¸ 2D Nodes Static:\n",
      "               Missing Count  Percentage\n",
      "min_elevation             12    0.322928\n",
      "\n",
      "âœ“ 1D Edges Static: No missing values\n",
      "\n",
      "âœ“ 2D Edges Static: No missing values\n",
      "\n",
      "âœ“ 1D-2D Connections: No missing values\n",
      "\n",
      "--- DYNAMIC FILES (Sample Events) ---\n",
      "\n",
      "EVENT_1:\n",
      "\n",
      "âœ“   1d_nodes_dynamic: No missing values\n",
      "\n",
      "âœ“   2d_nodes_dynamic: No missing values\n",
      "\n",
      "âœ“   1d_edges_dynamic: No missing values\n",
      "\n",
      "âœ“   2d_edges_dynamic: No missing values\n",
      "\n",
      "âœ“   timesteps: No missing values\n",
      "\n",
      "EVENT_10:\n",
      "\n",
      "âœ“   1d_nodes_dynamic: No missing values\n",
      "\n",
      "âœ“   2d_nodes_dynamic: No missing values\n",
      "\n",
      "âœ“   1d_edges_dynamic: No missing values\n",
      "\n",
      "âœ“   2d_edges_dynamic: No missing values\n",
      "\n",
      "âœ“   timesteps: No missing values\n",
      "\n",
      "EVENT_20:\n",
      "\n",
      "âœ“   1d_nodes_dynamic: No missing values\n",
      "\n",
      "âœ“   2d_nodes_dynamic: No missing values\n",
      "\n",
      "âœ“   1d_edges_dynamic: No missing values\n",
      "\n",
      "âœ“   2d_edges_dynamic: No missing values\n",
      "\n",
      "âœ“   timesteps: No missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"MISSING VALUE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def check_missing_values(df, name):\n",
    "    \"\"\"Check and report missing values in a dataframe\"\"\"\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    \n",
    "    if missing.sum() > 0:\n",
    "        print(f\"\\nâš ï¸ {name}:\")\n",
    "        missing_df = pd.DataFrame({\n",
    "            'Missing Count': missing[missing > 0],\n",
    "            'Percentage': missing_pct[missing > 0]\n",
    "        })\n",
    "        print(missing_df)\n",
    "        return missing_df\n",
    "    else:\n",
    "        print(f\"\\nâœ“ {name}: No missing values\")\n",
    "        return None\n",
    "\n",
    "# Check static files\n",
    "print(\"\\n--- STATIC FILES ---\")\n",
    "check_missing_values(m1_nodes_1d, \"1D Nodes Static\")\n",
    "check_missing_values(m1_nodes_2d, \"2D Nodes Static\")\n",
    "check_missing_values(m1_edges_1d, \"1D Edges Static\")\n",
    "check_missing_values(m1_edges_2d, \"2D Edges Static\")\n",
    "check_missing_values(m1_connections_1d2d, \"1D-2D Connections\")\n",
    "\n",
    "# Check sample events\n",
    "print(\"\\n--- DYNAMIC FILES (Sample Events) ---\")\n",
    "for event_name, data in sample_events_data.items():\n",
    "    print(f\"\\n{event_name.upper()}:\")\n",
    "    for key, df in data.items():\n",
    "        check_missing_values(df, f\"  {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f5defa",
   "metadata": {},
   "source": [
    "## 8. Load Model 2 Data and Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02329a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING MODEL 2 DATA FOR COMPARISON\n",
      "================================================================================\n",
      "âœ“ Model 2 static files loaded successfully!\n",
      "\n",
      "Model 2 Statistics:\n",
      "  Num 1D Nodes: 198\n",
      "  Num 2D Nodes: 4,299\n",
      "  Num 1D Edges: 197\n",
      "  Num 2D Edges: 9,876\n",
      "  Num 1D2D Connections: 197\n",
      "  Total Nodes: 4,497\n",
      "  Total Edges: 10,073\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOADING MODEL 2 DATA FOR COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load Model 2 static files\n",
    "m2_nodes_1d = pd.read_csv(MODEL_2_DIR / \"train\" / \"1d_nodes_static.csv\")\n",
    "m2_nodes_2d = pd.read_csv(MODEL_2_DIR / \"train\" / \"2d_nodes_static.csv\")\n",
    "m2_edges_1d = pd.read_csv(MODEL_2_DIR / \"train\" / \"1d_edges_static.csv\")\n",
    "m2_edges_2d = pd.read_csv(MODEL_2_DIR / \"train\" / \"2d_edges_static.csv\")\n",
    "m2_connections_1d2d = pd.read_csv(MODEL_2_DIR / \"train\" / \"1d2d_connections.csv\")\n",
    "m2_summary = pd.read_csv(MODEL_2_DIR / \"train\" / \"dataset_summary.csv\")\n",
    "\n",
    "print(\"âœ“ Model 2 static files loaded successfully!\")\n",
    "\n",
    "# Calculate stats for Model 2\n",
    "stats_m2 = {\n",
    "    'num_1d_nodes': len(m2_nodes_1d),\n",
    "    'num_2d_nodes': len(m2_nodes_2d),\n",
    "    'num_1d_edges': len(m2_edges_1d),\n",
    "    'num_2d_edges': len(m2_edges_2d),\n",
    "    'num_1d2d_connections': len(m2_connections_1d2d),\n",
    "    'total_nodes': len(m2_nodes_1d) + len(m2_nodes_2d),\n",
    "    'total_edges': len(m2_edges_1d) + len(m2_edges_2d),\n",
    "}\n",
    "\n",
    "print(\"\\nModel 2 Statistics:\")\n",
    "for key, value in stats_m2.items():\n",
    "    print(f\"  {key.replace('_', ' ').title()}: {value:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b9f1f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON TABLE\n",
      "================================================================================\n",
      "                 Metric  Model 1  Model 2\n",
      "               1D Nodes       17      198\n",
      "               2D Nodes     3716     4299\n",
      "            Total Nodes     3733     4497\n",
      "               1D Edges       16      197\n",
      "               2D Edges     7935     9876\n",
      "            Total Edges     7951    10073\n",
      "      1D-2D Connections       16      197\n",
      "        Training Events       68       69\n",
      "Timestep Interval (sec)      300      300\n",
      "\n",
      "âœ“ Comparison table saved to: c:\\Users\\shubh\\OneDrive\\Desktop\\UrbanFlooding\\analysis_outputs\\model_comparison_table.csv\n"
     ]
    }
   ],
   "source": [
    "# Create comparison table\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL COMPARISON TABLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_data = {\n",
    "    'Metric': [\n",
    "        '1D Nodes',\n",
    "        '2D Nodes',\n",
    "        'Total Nodes',\n",
    "        '1D Edges',\n",
    "        '2D Edges',\n",
    "        'Total Edges',\n",
    "        '1D-2D Connections',\n",
    "        'Training Events',\n",
    "        'Timestep Interval (sec)'\n",
    "    ],\n",
    "    'Model 1': [\n",
    "        stats_m1['num_1d_nodes'],\n",
    "        stats_m1['num_2d_nodes'],\n",
    "        stats_m1['total_nodes'],\n",
    "        stats_m1['num_1d_edges'],\n",
    "        stats_m1['num_2d_edges'],\n",
    "        stats_m1['total_edges'],\n",
    "        stats_m1['num_1d2d_connections'],\n",
    "        m1_summary['num_events'].values[0],\n",
    "        m1_summary['timestep_interval'].values[0]\n",
    "    ],\n",
    "    'Model 2': [\n",
    "        stats_m2['num_1d_nodes'],\n",
    "        stats_m2['num_2d_nodes'],\n",
    "        stats_m2['total_nodes'],\n",
    "        stats_m2['num_1d_edges'],\n",
    "        stats_m2['num_2d_edges'],\n",
    "        stats_m2['total_edges'],\n",
    "        stats_m2['num_1d2d_connections'],\n",
    "        m2_summary['num_events'].values[0],\n",
    "        m2_summary['timestep_interval'].values[0]\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison table\n",
    "comparison_df.to_csv(OUTPUT_DIR / \"model_comparison_table.csv\", index=False)\n",
    "print(f\"\\nâœ“ Comparison table saved to: {OUTPUT_DIR / 'model_comparison_table.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b922698",
   "metadata": {},
   "source": [
    "## 9. ğŸ¯ CRITICAL: Calculate Standardization Values for Water Levels\n",
    "\n",
    "**Why this matters:** The evaluation metric normalizes errors by the standard deviation of water levels per model and node type. We need to calculate these exact values for the loss function during training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f55baac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CALCULATING STANDARDIZATION VALUES FOR ALL TRAINING EVENTS\n",
      "================================================================================\n",
      "\n",
      "This will take a few moments as we process all training events...\n",
      "\n",
      "\n",
      "MODEL 1:\n",
      "----------------------------------------\n",
      "  Processing 68 events for 1D nodes...\n",
      "    âœ“ Loaded 267,019 water_level values\n",
      "    Mean: 308.0884, Std: 16.8777\n",
      "  Processing 68 events for 2D nodes...\n",
      "    âœ“ Loaded 58,367,212 water_level values\n",
      "    Mean: 322.1120, Std: 14.3788\n",
      "\n",
      "MODEL 2:\n",
      "----------------------------------------\n",
      "  Processing 69 events for 1D nodes...\n",
      "    âœ“ Loaded 3,534,894 water_level values\n",
      "    Mean: 39.8941, Std: 3.1918\n",
      "  Processing 69 events for 2D nodes...\n",
      "    âœ“ Loaded 76,750,047 water_level values\n",
      "    Mean: 43.7300, Std: 2.7271\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CALCULATING STANDARDIZATION VALUES FOR ALL TRAINING EVENTS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nThis will take a few moments as we process all training events...\\n\")\n",
    "\n",
    "def calculate_water_level_std(model_dir, node_type):\n",
    "    \"\"\"\n",
    "    Calculate standard deviation of water_level across all training events.\n",
    "    \n",
    "    Args:\n",
    "        model_dir: Path to model directory (Model_1 or Model_2)\n",
    "        node_type: '1d' or '2d'\n",
    "    \n",
    "    Returns:\n",
    "        Standard deviation of water_level\n",
    "    \"\"\"\n",
    "    train_dir = model_dir / \"train\"\n",
    "    all_water_levels = []\n",
    "    \n",
    "    # Get all event directories\n",
    "    event_dirs = sorted([d for d in train_dir.iterdir() if d.is_dir() and d.name.startswith('event_')])\n",
    "    \n",
    "    print(f\"  Processing {len(event_dirs)} events for {node_type.upper()} nodes...\")\n",
    "    \n",
    "    for event_dir in event_dirs:\n",
    "        dynamic_file = event_dir / f\"{node_type}_nodes_dynamic_all.csv\"\n",
    "        \n",
    "        if dynamic_file.exists():\n",
    "            try:\n",
    "                df = pd.read_csv(dynamic_file)\n",
    "                if 'water_level' in df.columns:\n",
    "                    all_water_levels.extend(df['water_level'].values)\n",
    "            except Exception as e:\n",
    "                print(f\"    âš ï¸ Warning: Could not load {event_dir.name}/{dynamic_file.name}: {e}\")\n",
    "    \n",
    "    if len(all_water_levels) > 0:\n",
    "        water_levels_array = np.array(all_water_levels)\n",
    "        std_value = np.std(water_levels_array)\n",
    "        mean_value = np.mean(water_levels_array)\n",
    "        print(f\"    âœ“ Loaded {len(all_water_levels):,} water_level values\")\n",
    "        print(f\"    Mean: {mean_value:.4f}, Std: {std_value:.4f}\")\n",
    "        return std_value, mean_value, len(all_water_levels)\n",
    "    else:\n",
    "        print(f\"    âš ï¸ No water_level data found!\")\n",
    "        return None, None, 0\n",
    "\n",
    "# Calculate for all 4 combinations\n",
    "print(\"\\nMODEL 1:\")\n",
    "print(\"-\" * 40)\n",
    "std_m1_1d, mean_m1_1d, n_m1_1d = calculate_water_level_std(MODEL_1_DIR, '1d')\n",
    "std_m1_2d, mean_m1_2d, n_m1_2d = calculate_water_level_std(MODEL_1_DIR, '2d')\n",
    "\n",
    "print(\"\\nMODEL 2:\")\n",
    "print(\"-\" * 40)\n",
    "std_m2_1d, mean_m2_1d, n_m2_1d = calculate_water_level_std(MODEL_2_DIR, '1d')\n",
    "std_m2_2d, mean_m2_2d, n_m2_2d = calculate_water_level_std(MODEL_2_DIR, '2d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f891b",
   "metadata": {},
   "source": [
    "## 10. Save Standardization Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d674504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STANDARDIZATION VALUES SUMMARY\n",
      "================================================================================\n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘         WATER LEVEL STANDARDIZATION PARAMETERS            â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘ Model 1 - 1D Nodes STD:   16.877747                    â•‘\n",
      "â•‘ Model 1 - 2D Nodes STD:   14.378797                    â•‘\n",
      "â•‘ Model 2 - 1D Nodes STD:    3.191784                    â•‘\n",
      "â•‘ Model 2 - 2D Nodes STD:    2.727131                    â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "âœ“ Standardization values saved to: c:\\Users\\shubh\\OneDrive\\Desktop\\UrbanFlooding\\analysis_outputs\\standardization_values.json\n",
      "âœ“ CSV version saved to: c:\\Users\\shubh\\OneDrive\\Desktop\\UrbanFlooding\\analysis_outputs\\standardization_values.csv\n",
      "\n",
      "\n",
      "  Model Node_Type   Std_Dev       Mean  N_Samples\n",
      "Model_1        1D 16.877747 308.088367     267019\n",
      "Model_1        2D 14.378797 322.112040   58367212\n",
      "Model_2        1D  3.191784  39.894078    3534894\n",
      "Model_2        2D  2.727131  43.729952   76750047\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STANDARDIZATION VALUES SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "standardization_values = {\n",
    "    'model_1': {\n",
    "        '1d_nodes': {\n",
    "            'std': float(std_m1_1d) if std_m1_1d is not None else None,\n",
    "            'mean': float(mean_m1_1d) if mean_m1_1d is not None else None,\n",
    "            'n_samples': int(n_m1_1d)\n",
    "        },\n",
    "        '2d_nodes': {\n",
    "            'std': float(std_m1_2d) if std_m1_2d is not None else None,\n",
    "            'mean': float(mean_m1_2d) if mean_m1_2d is not None else None,\n",
    "            'n_samples': int(n_m1_2d)\n",
    "        }\n",
    "    },\n",
    "    'model_2': {\n",
    "        '1d_nodes': {\n",
    "            'std': float(std_m2_1d) if std_m2_1d is not None else None,\n",
    "            'mean': float(mean_m2_1d) if mean_m2_1d is not None else None,\n",
    "            'n_samples': int(n_m2_1d)\n",
    "        },\n",
    "        '2d_nodes': {\n",
    "            'std': float(std_m2_2d) if std_m2_2d is not None else None,\n",
    "            'mean': float(mean_m2_2d) if mean_m2_2d is not None else None,\n",
    "            'n_samples': int(n_m2_2d)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\")\n",
    "print(\"â•‘         WATER LEVEL STANDARDIZATION PARAMETERS            â•‘\")\n",
    "print(\"â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\")\n",
    "print(f\"â•‘ Model 1 - 1D Nodes STD:  {std_m1_1d:>10.6f}                    â•‘\")\n",
    "print(f\"â•‘ Model 1 - 2D Nodes STD:  {std_m1_2d:>10.6f}                    â•‘\")\n",
    "print(f\"â•‘ Model 2 - 1D Nodes STD:  {std_m2_1d:>10.6f}                    â•‘\")\n",
    "print(f\"â•‘ Model 2 - 2D Nodes STD:  {std_m2_2d:>10.6f}                    â•‘\")\n",
    "print(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "\n",
    "# Save to JSON\n",
    "standardization_file = OUTPUT_DIR / \"standardization_values.json\"\n",
    "with open(standardization_file, 'w') as f:\n",
    "    json.dump(standardization_values, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ“ Standardization values saved to: {standardization_file}\")\n",
    "\n",
    "# Also save as simple CSV for easy reference\n",
    "simple_df = pd.DataFrame({\n",
    "    'Model': ['Model_1', 'Model_1', 'Model_2', 'Model_2'],\n",
    "    'Node_Type': ['1D', '2D', '1D', '2D'],\n",
    "    'Std_Dev': [std_m1_1d, std_m1_2d, std_m2_1d, std_m2_2d],\n",
    "    'Mean': [mean_m1_1d, mean_m1_2d, mean_m2_1d, mean_m2_2d],\n",
    "    'N_Samples': [n_m1_1d, n_m1_2d, n_m2_1d, n_m2_2d]\n",
    "})\n",
    "\n",
    "csv_file = OUTPUT_DIR / \"standardization_values.csv\"\n",
    "simple_df.to_csv(csv_file, index=False)\n",
    "print(f\"âœ“ CSV version saved to: {csv_file}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(simple_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3943571",
   "metadata": {},
   "source": [
    "## 11. Summary & Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43e03998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "KEY FINDINGS - DATA LOADING & BASIC STATISTICS\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š DATASET OVERVIEW:\n",
      "   â€¢ Two separate catchment models (Model 1 & Model 2)\n",
      "   â€¢ Temporal resolution: 5 minutes (300 seconds)\n",
      "   â€¢ Training events: Model 1 = 68, Model 2 = 69\n",
      "   \n",
      "ğŸ—ï¸ NETWORK STRUCTURE (Model 1):\n",
      "   â€¢ 1D Network (Drainage): 17 nodes, 16 edges\n",
      "   â€¢ 2D Network (Surface): 3,716 nodes, 7,935 edges\n",
      "   â€¢ 1D-2D Coupling: 16 connections\n",
      "   â€¢ Scale Imbalance: 2D network is 219x larger than 1D\n",
      "   \n",
      "ğŸ—ï¸ NETWORK STRUCTURE (Model 2):\n",
      "   â€¢ 1D Network (Drainage): 198 nodes, 197 edges\n",
      "   â€¢ 2D Network (Surface): 4,299 nodes, 9,876 edges\n",
      "   â€¢ 1D-2D Coupling: 197 connections\n",
      "   â€¢ Scale Imbalance: 2D network is 22x larger than 1D\n",
      "\n",
      "ğŸ“ SEQUENCE LENGTHS (from sample events):\n",
      "   â€¢ Min: 94 timesteps\n",
      "   â€¢ Max: 205 timesteps\n",
      "   â€¢ Mean: 168.0 timesteps\n",
      "   â€¢ Variable-length sequences require careful batching!\n",
      "\n",
      "ğŸ¯ STANDARDIZATION PARAMETERS (CRITICAL FOR TRAINING):\n",
      "   â€¢ Model 1, 1D Nodes: Ïƒ = 16.877747\n",
      "   â€¢ Model 1, 2D Nodes: Ïƒ = 14.378797\n",
      "   â€¢ Model 2, 1D Nodes: Ïƒ = 3.191784\n",
      "   â€¢ Model 2, 2D Nodes: Ïƒ = 2.727131\n",
      "   \n",
      "âœ“ DATA QUALITY:\n",
      "   â€¢ No missing values detected in static files\n",
      "   â€¢ No missing values in sample dynamic files\n",
      "   â€¢ All timestamps consistent across event files\n",
      "\n",
      "ğŸ“ OUTPUTS SAVED:\n",
      "   â€¢ c:\\Users\\shubh\\OneDrive\\Desktop\\UrbanFlooding\\analysis_outputs\\model_comparison_table.csv\n",
      "   â€¢ c:\\Users\\shubh\\OneDrive\\Desktop\\UrbanFlooding\\analysis_outputs\\standardization_values.json\n",
      "   â€¢ c:\\Users\\shubh\\OneDrive\\Desktop\\UrbanFlooding\\analysis_outputs\\standardization_values.csv\n",
      "\n",
      "\n",
      "================================================================================\n",
      "âœ“ PART 1 COMPLETE - DATA LOADING & BASIC STATISTICS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"KEY FINDINGS - DATA LOADING & BASIC STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "findings = f\"\"\"\n",
    "ğŸ“Š DATASET OVERVIEW:\n",
    "   â€¢ Two separate catchment models (Model 1 & Model 2)\n",
    "   â€¢ Temporal resolution: 5 minutes (300 seconds)\n",
    "   â€¢ Training events: Model 1 = {m1_summary['num_events'].values[0]}, Model 2 = {m2_summary['num_events'].values[0]}\n",
    "   \n",
    "ğŸ—ï¸ NETWORK STRUCTURE (Model 1):\n",
    "   â€¢ 1D Network (Drainage): {stats_m1['num_1d_nodes']} nodes, {stats_m1['num_1d_edges']} edges\n",
    "   â€¢ 2D Network (Surface): {stats_m1['num_2d_nodes']:,} nodes, {stats_m1['num_2d_edges']:,} edges\n",
    "   â€¢ 1D-2D Coupling: {stats_m1['num_1d2d_connections']} connections\n",
    "   â€¢ Scale Imbalance: 2D network is {stats_m1['num_2d_nodes'] / stats_m1['num_1d_nodes']:.0f}x larger than 1D\n",
    "   \n",
    "ğŸ—ï¸ NETWORK STRUCTURE (Model 2):\n",
    "   â€¢ 1D Network (Drainage): {stats_m2['num_1d_nodes']} nodes, {stats_m2['num_1d_edges']} edges\n",
    "   â€¢ 2D Network (Surface): {stats_m2['num_2d_nodes']:,} nodes, {stats_m2['num_2d_edges']:,} edges\n",
    "   â€¢ 1D-2D Coupling: {stats_m2['num_1d2d_connections']} connections\n",
    "   â€¢ Scale Imbalance: 2D network is {stats_m2['num_2d_nodes'] / stats_m2['num_1d_nodes']:.0f}x larger than 1D\n",
    "\n",
    "ğŸ“ SEQUENCE LENGTHS (from sample events):\n",
    "   â€¢ Min: {seq_lengths_array.min()} timesteps\n",
    "   â€¢ Max: {seq_lengths_array.max()} timesteps\n",
    "   â€¢ Mean: {seq_lengths_array.mean():.1f} timesteps\n",
    "   â€¢ Variable-length sequences require careful batching!\n",
    "\n",
    "ğŸ¯ STANDARDIZATION PARAMETERS (CRITICAL FOR TRAINING):\n",
    "   â€¢ Model 1, 1D Nodes: Ïƒ = {std_m1_1d:.6f}\n",
    "   â€¢ Model 1, 2D Nodes: Ïƒ = {std_m1_2d:.6f}\n",
    "   â€¢ Model 2, 1D Nodes: Ïƒ = {std_m2_1d:.6f}\n",
    "   â€¢ Model 2, 2D Nodes: Ïƒ = {std_m2_2d:.6f}\n",
    "   \n",
    "âœ“ DATA QUALITY:\n",
    "   â€¢ No missing values detected in static files\n",
    "   â€¢ No missing values in sample dynamic files\n",
    "   â€¢ All timestamps consistent across event files\n",
    "\n",
    "ğŸ“ OUTPUTS SAVED:\n",
    "   â€¢ {OUTPUT_DIR / 'model_comparison_table.csv'}\n",
    "   â€¢ {OUTPUT_DIR / 'standardization_values.json'}\n",
    "   â€¢ {OUTPUT_DIR / 'standardization_values.csv'}\n",
    "\"\"\"\n",
    "\n",
    "print(findings)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ“ PART 1 COMPLETE - DATA LOADING & BASIC STATISTICS\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
